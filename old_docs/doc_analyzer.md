This document describes the state of the doc_analyzer module at the end of the 2017 summer research session

# Overview

The doc_analyzer module performs posting and translation tuple generation when a new document is retreived from the fetcher. The main function that is of interest to the index is the indexUpdate function, which retreives a new document from the fetcher and inserts generated postings into the index, while updating the Translation Table with generated translations and replacing the old document in the document store.

There are two submodules included in doc_analyzer; the Matcher module and the Structures module. The Matcher module implements the code needed to generate the optimal set of postings, and the Structures module implements the Document Store and Translation Table using cpp_redis, a library that serves as a redis client.

# Matcher Module

The matcher module generates the optimal posting and translation tuple set given two versions of a document, the process of which is described next. First, a set of all possible common blocks of text is generated. A common block of text is defined as a string of words that can be found in both files. Next, a directed graph is generated using the set of common blocks. The graph is generated where each vertice represents a common block of text, each edge represents whether the next block is a valid selection, and each edge weight represents the amount of common text the next vertex has. Thus the goal is to find the optimal path through the graph that maximizes the amount of text saved while minimizing the number of blocks selected. Selecting a block of text to save has a cost since the more blocks we save, the longer the generated translation list for that document becomes. Finally, we use the set of saved common blocks to determine which text was deleted from the old document and inserted into the new document. Nonpositional postings are generated from deletions and insertions, while Positional postings are generated from insertions only.

The specific function of each module is described in the next sections

## String Encoder

The String Encoder encodes two versions of a document into a vector of integers, where each integer acts as a unique identifier for a word. This allows us to index the document on a word-by-word basis, instead of having to deal with a string of individual characters. Since the index also requires the set of terms that appear exclusively in either version of the document, the String Encoder generates those lists as its encoding both documents

## Block

The Block file contains functions that generate the complete set of common blocks between two document versions, as well as the definition of the Block struct.

### getCommonBlocks

This function generates all "candidate" blocks of common text that are of a minimum size. First, every possible substring of size minsize from the old document is stored into a map, which is done by sliding a window of length minsize through the old document and storing every substring found. This process is then repeated in the new document, except every substring found in the new document is looked up in the map to see if it matches some substring in the old document. If the substrings match, then the matched pair is stored in a Block along with the actual common text.

### extendBlocks

This function attempts to extend the "candidate" blocks generated by the getCommonBlocks function. Because getCommonBlocks naively generates all possible blocks of length minsize, a longer run of common text would end up being composed of many overlapping candidate blocks. Thus this function attempts to extend blocks and remove redundant blocks that are overlapped by the extended blocks.

### resolveIntersections

This function resolves any leftover overlaps between common blocks after extendBlocks has run. The simplest case of this would be if two blocks overlap in the old version but not in the new version. We can take either block exclusively, or take one block entirely and the other block without the overlapping section. Since we don't know which possibility is optimal, we would like to have both options available when we decide which is optimal. This function resolves these kinds of intersection, plus more complicated cases.

## Graph

The Graph file contains the BlockGraph class along with functions to perform a topological sort. The BlockGraph class is designed specifically to hold blocks and is implemented using adjacency lists.

### BlockGraph.BlockGraph

The BlockGraph constructor takes in a list of common blocks and fills in the adjacency list for each block. A block is a valid neighbor if it appears strictly after the current block (the neighbor's common text appears after the current block's common text in both the old and new document without overlaps).

### BlockGraph.getAdjacencyList

Gets the adjacency list associated with a common block

### BlockGraph.insertNeighbor

Inserts a neighbor into a block's adjacency list. The adjacency list is created if it doesn't yet exist

### BlockGraph.getAllVertices

Returns a list of all blocks stored in the graph. More specifically, a list of all blocks that have an adjacency list are returned.

### topologicalSort

Topologically sorts a BlockGraph. This is done using a recursive DFS and reversing the order that the nodes were visited in.

### explore

The recursive helper function for topologicalSort. Explores all nodes connected to the current node using DFS.

## Distance Table

The DistanceTable file contains the DistanceTable class which tabulates distance data when traversing the graph. Any path through the graph of common blocks represents a valid selection of common blocks, so the goal is to find a path through the graph that maximizes saved text and minimizes the number of blocks taken. This is accomplished by exploring the graph using a modified version of the longest-path algorithm for DAGs. However, instead of finding only the longest path up to a certain node, a longest path is stored for each possible number of steps ending with the current node. Each node is associated with a table that stores the longest path given k number of steps. This way, we can determine the best possible path for any number of steps through the graph. Using this information, we can determine when adding an extra block does not save enough common text to justify the cost of adding a translation entry.

### DistanceTable.TableEntry

This struct represents a single entry in the table that is associated with a node in the graph. Each node is associated with a vector of entries, which represents the table. An entry contains the number of steps taken, the amount of text saved, which block it's associated with, and which block came previously.

### DistanceTable.DistanceTable

The constructor initializes every node in the graph with a table and fills out the table for each node. Each node is initialized with a table containing one entry, which essentially states that every node in the graph can be reached in one step, with a saving of the given node's common text. Each node's table is then filled out, according to the following algorithm. We visit each node in the graph in topological order. For each node in topological order, a list of its neighbors is retrieved. For each neighbor, the current node's table is "merged" into the neighbor's table, using DistanceTable.mergeIntoNext.

### DistanceTable.initVertex

This helper method for the DistanceTable constructor initializes a given vertex with a table. The table contains one entry that states that in one step the best path that ends in the given node is simply a path containing the node.

### DistanceTable.mergeIntoNext

This is a helper method for the DistanceTable constructor that builds the table associated with a node. Given a "previous" node and a "next" node, this function "merges" the previous into the next (In the context of the constructor, the neighbor is "next" and the current is "previous"). This is done by taking every entry in the previous table, incrementing its step variable and adding the next node's weight (amount of common text saved) to its total saved variable, then comparing this result to the next table's entry for the equivalent number of steps. If the new entry is greater, then the new entry is written into the next node.

### DistanceTable.findAllBestPaths

This method finds the best path for every number of steps through the graph. This is done by iterating through every node's table, and selecting the entry that has the best savings for a given number of steps.

### DistanceTable.findOptimalPath

This method is the main method to be called from this class. It returns an optimal vector of common blocks to save from the two documents. First, a table of the savings possible with every number of steps is found using findAllBestPaths. We then evaluate each entry of the table step by step using a cost function to determine if it is worth taking another step. The cost function is defined as *ax-y*, where *a* is a constant passed into the method, *x* is the total number of blocks taken, and *y* is the marginal amount of text saved. As long as the cost function is positive, the method will keep taking additional steps. Once an optimal number of steps is calculated, the method then uses tracePath to trace the path of the optimal end node and obtain the list of common blocks to save.

### DistanceTable.tracePath

This method traces the path leading up to a given table entry. This is done by simply calling getPreviousEntry repeatedly and saving every block that is explored.

### DistanceTable.getPreviousEntry

This is a helper method for the tracePath function which finds the entry that lead to the given table entry. This is accomplished by finding the previous node, then getting the table entry associated with that node at position steps-1. This works because we filled out the table in topological order, so no path can be overwritten.

## Translate

This file deals with generating translations and applying them.

### Translation

This struct encapsulates a translation tuple into a struct for convenience. A translation tuple contains the location of an edited block of text in the old document, the length of the edited text in the old document, and the length of the edited text in the new document. Each translation applies to one Basic Edit Operation (BEO), which is defined to be an edit operation that consists of a deletion then insertion.

### getTranslations

This function obtains a list of translations given a list of common blocks and the length of the old and new document. This is done by indexing over the text between common blocks. The edited text between common blocks represents one BEO in the document, so for each BEO a translation is generated. Since later translations are affected by translations earlier in the document, a shift variable is kept that represents how the text moves with each BEO.

### applyTranslation

This function applys a single translation to a given index. The index can either remain unchanged, be shifted, or considered invalid.

## Matcher

This file (along with Translate) provides the high-level functionality of this module, namely generating the optimal set of postings given two versions of a document.

### getCommonBlocks

This function obtains the list of optimal common blocks to keep using the process detailed in the module description.

### getPostings

This function returns two lists of positional and non-positional postings generated from the two versions of a document. Similarly to the getTranslations function, this function generates postings by indexing the edited sections of a document. It first loops through the old version of the document, generating non-positional postings from the deleted text. It then loops through the new version of the document, generating both non-positional and positional postings from the inserted text.

# Structures Module

This module contains the definitions for two data structures that the doc_analyzer uses, the Document Store and Translation Table. This module may be moved in the future for convenience.

## Document Store

This file implements the data structure to store all of the indexed documents along with necessary metadata

### DocumentTuple

This struct bundles all of the data fields stored in the document store for convenient transfer of a document with its metadata

### DocumentStore.DocumentStore

The constructor initializes the redis client and sets the nextid variable to 0 if it doesn't exist. Documents in the document store are given incremental ids for use in the index, and so the variable to keep track of the next available docid is necessary. Since the database can persist between application runs, the nextid variable is kept in the database.

### DocumentStore.getDocument

This method obtains the document associated with the given url. Since each document is stored as a list of strings in the database, this method converts those strings into a valid DocumentTuple and returns it. If no document is found, an empty document is returned.

### DocumentStore.insertDocument

This method creates a DocumentTuple to associate with a url in the database. If the document already exists, it is replaced with the new document.

### DocumentStore.getNextDocID

This method returns the next available docid. Currently included for debugging purposes, as it seems unnecessary to keep.

## TranslationTable

This file implements the translation table associated with every document

### TranslationTable.TranslationTable

The constructor functions exactly like the DocumentStore constructor, except it does not need to initialize any variables.

### TranslationTable.apply

This method applies a given index onto the document's translation list. This is done by sequentially applying each individual translation onto the index. The fragID of the posting essentially states which "version" of the document the index was valid in, which allows us to skip translations that correspond to earlier versions of the document. If the index becomes invalidated at any point, the method stops and returns a negative position to indicate an invalid state.

### TranslationTable.insert

Inserts a vector of translations into the appropriate translation list. Note that these translations are appended to the given translation list.

### TranslationTable.erase

Deletes the translation list associated with a docID. Necessary if the document gets completely reindexed due to the translation list getting too long.

### transToString

Converts a Translation struct into a string of the format loc-oldlen-newlen. This is necessary when storing a translation into the database.

### stringToTrans

Converts a string of the format loc-oldlen-newlen into a valid Translation Struct. This is necessary when retrieving a Translation from the database.